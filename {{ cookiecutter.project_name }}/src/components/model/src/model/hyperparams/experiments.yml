LGBMRegressor:
  base_trials:
    default:
      objective: "regression"
      learning_rate: 0.1
      num_leaves: 31
      max_depth: -1 
      n_estimators: 100
      min_data_in_leaf: 20
      min_sum_hessian_in_leaf: 1.e-3
      bagging_fraction: 1.0
      reg_alpha: 0.0
      reg_lambda: 0.0
      subsample_freq: 0
      feature_fraction: 1.0
      feature_fraction_bynode: 1.0
      max_delta_step: 0.0
      max_bin: 255
    best_found:
      objective: "regression"
      learning_rate: 0.09914121383443131
      num_leaves: 57
      max_depth: 10
      n_estimators: 514
      min_data_in_leaf: 20
      min_sum_hessian_in_leaf: 1.e-3
      reg_alpha: 1.4646671948482264
      reg_lambda: 0.7315228384878054
      bagging_fraction: 0.9373650999450522
      subsample_freq: 4
      feature_fraction: 1.0
      feature_fraction_bynode: 1.0
      max_delta_step: 0.0
      max_bin: 255
  grid:
    objective: ["regression", "regression_l1", "huber", "fair", "poisson", "mape", "gamma", "tweedie"]
    learning_rate: [1.e-5, 0.1]
    num_leaves: [2, 64]
    max_depth: [-1, 20]
    n_estimators: [100, 1000]
    min_data_in_leaf: [1, 40]
    min_sum_hessian_in_leaf: [1.e-5, 10]
    bagging_fraction: [0.5, 1.0]
    reg_alpha: [0.0, 100]
    reg_lambda: [0.0, 100]
    subsample_freq: [0, 10]
    feature_fraction: [0.8, 1.0]
    feature_fraction_bynode: [0.8, 1.0]
    max_delta_step: [0.0, 10.0]
    max_bin: [128, 512]

XGBRegressor:
  base_trials:
    default:
      learning_rate: 0.3
      max_depth: 6
      reg_alpha: 0
      reg_lambda: 1
      subsample: 1
  grid:
    learning_rate: [1.e-5, 0.1]
    max_depth: [1, 10]
    reg_alpha: [1.e-5, 100]
    reg_lambda: [1.e-5, 100]
    subsample: [0.85, 1]


CatBoostRegressor:
  base_trials:
    default:
      nan_mode: 'Min'
      eval_metric: 'RMSE'
      
      sampling_frequency: 'PerTree'
      leaf_estimation_method: 'Newton'
      random_score_type: 'NormalWithModelSizeDecrease'
      grow_policy: 'SymmetricTree'
      penalties_coefficient: 1
      boosting_type: 'Plain'
      model_shrink_mode: 'Constant'
      feature_border_type: 'GreedyLogSum'
      l2_leaf_reg: 3
      random_strength: 1
      rsm: 1
      subsample: 0.800000011920929
      random_seed: 42
      depth: 6
      posterior_sampling: False
      model_shrink_rate: 0
      loss_function': 'RMSE'
      learning_rate: 0.0637660026550293
      score_function: 'Cosine'
      bootstrap_type: 'MVS'
      max_leaves: 64

    best_found:
      nan_mode: 'Min'
      eval_metric: 'RMSE' 
      sampling_frequency: 'PerTree'
      leaf_estimation_method: 'Newton'
      random_score_type: 'NormalWithModelSizeDecrease'
      grow_policy: 'SymmetricTree'
      penalties_coefficient: 1
      boosting_type: 'Plain'
      model_shrink_mode: 'Constant'
      feature_border_type: 'GreedyLogSum'
      l2_leaf_reg: 0.5092358708053079
      random_strength: 1
      rsm: 1
      subsample: 0.9897972353935439
      random_seed': 42
      depth: 9
      posterior_sampling: False
      model_shrink_rate: 0
      loss_function': 'RMSE'
      learning_rate: 0.09163475026555298
      score_function: 'Cosine'
      bootstrap_type: 'MVS'
      max_leaves: 64
    best_small:
      objective: 'RMSE'
      learning_rate: 0.23846390993214034
      depth: 6
      l2_leaf_reg: 49.251774456709455
      subsample: 0.8792864481697067
      bootstrap_type: 'MVS'
      leaf_estimation_method: 'Newton'
      sampling_frequency: 'PerTree'
      boosting_type: 'Plain'
      model_shrink_mode: 'Constant'
      feature_border_type: 'GreedyLogSum'
      random_strength: 1
      rsm: 1
      model_size_reg: 0.5

  grid:
    objective: ["RMSE"]
    learning_rate: [1.e-5, 3.e-1]
    grow_policy: ['SymmetricTree']
    random_score_type: ["Gumbel", "NormalWithModelSizeDecrease"]
    penalties_coefficient: [0.5, 2.0]
    depth: [5, 10]
    l2_leaf_reg: [1.e-5, 100]
    subsample: [0.8, 1]
    bootstrap_type: ["MVS", "Bernoulli"]
    leaf_estimation_method: ["Newton", "Gradient"]
    sampling_frequency: ["PerTree", "PerTreeLevel"]
    boosting_type: ["Plain", "Ordered"]
    model_shrink_mode: ["Constant", "Decreasing"]
    feature_border_type: ["GreedyLogSum", "Median", "Uniform", "MinEntropy"]
    # posterior_sampling: [true, false] # TODO: Parse booleans in tuning
    score_function: ["Cosine", "L2"]
    random_strength: [0.5, 2]
    #model_shrink_rate: [0, 0.9]
    rsm: [0.1, 1]